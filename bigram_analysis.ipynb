{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "1f39ba46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "[nltk_data] Downloading package punkt to /home/kwaks/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import fasttext as ft\n",
    "import translators as ts\n",
    "ft_model = ft.load_model(\"lid.176.bin\")\n",
    "from nrclex import NRCLex\n",
    "import spacy \n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "2ba1fdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-11 00:37:22.693370: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-11 00:37:22.693387: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-11 00:37:22.693398: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Kwakuter): /proc/driver/nvidia/version does not exist\n",
      "2022-07-11 00:37:22.693549: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "preprocessor = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-preprocess/2\")\n",
    "encoderLabse = hub.KerasLayer(\"https://tfhub.dev/google/LaBSE/2\")\n",
    "\n",
    "def normalization(embeddings):\n",
    "    norms = np.linalg.norm(embeddings, 2, axis=1, keepdims=True)\n",
    "    return embeddings/norms\n",
    "\n",
    "def val_ct_dict(obj):\n",
    "    unique, counts = np.unique(obj, return_counts=True)\n",
    "    val_ct = dict(zip(unique, counts))\n",
    "    val_ct = dict(reversed(sorted(val_ct.items(), key=lambda item: item[1])))\n",
    "    return val_ct\n",
    "\n",
    "def embedd(sentence):\n",
    "    if isinstance(sentence, str):\n",
    "        embedding = tf.constant([sentence])\n",
    "    else:\n",
    "        embedding = tf.constant(sentence)\n",
    "    embedding = encoderLabse(preprocessor(embedding))[\"default\"]\n",
    "    embedding = normalization(embedding)\n",
    "    return embedding\n",
    "\n",
    "def embedd_list(list_obj):\n",
    "    embedded = np.zeros((len(list_obj), 768))\n",
    "    with tqdm(total=len(list_obj)) as pbar:\n",
    "        for i in range(len(list_obj)):\n",
    "            embedded[i] = embedd(list_obj[i])\n",
    "            pbar.update(1)\n",
    "    return embedded\n",
    "\n",
    "def val_ct_dict(obj):\n",
    "    unique, counts = np.unique(obj, return_counts=True)\n",
    "    val_ct = dict(zip(unique, counts))\n",
    "    val_ct = dict(reversed(sorted(val_ct.items(), key=lambda item: item[1])))\n",
    "    return val_ct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d31621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.ExcelFile('tweets_sample.xlsx')\n",
    "langs = tweets.sheet_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7a2cf633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_emotional(text):\n",
    "    emotion = NRCLex(text)\n",
    "    emo = emotion.top_emotions\n",
    "    if not sum(dict(emo).values()):\n",
    "        return (\"neutral\")\n",
    "    else:\n",
    "        return emo\n",
    "    \n",
    "def process(text,retweet_name):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    if isinstance(retweet_name, str) and len(retweet_name):\n",
    "        text = re.sub(r'@\\w+', retweet_name.replace(\" \", \"_\"), text)\n",
    "    else:\n",
    "        text = re.sub(r'@', \"\", text)\n",
    "    sent = text.split(\".\")\n",
    "    for s in sent:\n",
    "        if len(s)>1:\n",
    "            print(\"-----\")\n",
    "            l = ft_model.predict(s)[0][0][-2:]\n",
    "            print(l)\n",
    "            if l != 'en':\n",
    "                s = ts.google(s, from_language=l, to_language='en')\n",
    "\n",
    "            emo = get_emotional(s)\n",
    "            ents = [t for t in nlp(s).ents]\n",
    "            print(s,ents,emo)\n",
    "\n",
    "    print(\"\\n____________________________________________________________________________________\\n\")   \n",
    "    words = text\n",
    "    return pd.Series([text, words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "feac5124",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {}\n",
    "l_ = [\"UK.2\"]\n",
    "from spacy.lang.en import STOP_WORDS\n",
    "prefix_re = re.compile('''^\\$[a-zA-Z0-9]''')\n",
    "def custom_tokenizer(nlp):\n",
    "        return spacy.tokenizer.Tokenizer(nlp.vocab, prefix_search=prefix_re.search)\n",
    "nlp.tokenizer = custom_tokenizer(nlp) \n",
    "\n",
    "def clear_lemma(text):\n",
    "    text = re.sub(r'@', '', text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'#\\S+', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n ', '', text)\n",
    "    text = re.sub(r'@', '', text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'#\\S+', '', text)\n",
    "    text = re.sub(r'\\.|\\,|\\:', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
    "    text = re.sub(r'prime minister', 'prime_minister', text)\n",
    "    text = re.sub(r'pm', 'prime_minister', text)\n",
    "    text = re.sub(r'united kingdom', 'united kingdom', text)\n",
    "    text_lemmatized = [t.lemma_ for t in nlp(text) if t.lemma_ not in STOP_WORDS and \n",
    "                       not re.match(r'\\s',t.lemma_)\n",
    "                      and len(t.lemma_)>1]\n",
    "    return text_lemmatized \n",
    "\n",
    "def bi_tri_grams(text):\n",
    "    return pd.Series([list(nltk.bigrams(text)), list(nltk.trigrams(text))])\n",
    "\n",
    "for lang in l_:\n",
    "    corpus = tweets.parse(lang)\n",
    "    corpus.text = corpus.text.apply(lambda x: clear_lemma(x))\n",
    "    corpus[[\"bi\",\"tri\"]] = corpus.text.apply(lambda x: bi_tri_grams(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "21f94df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = np.array([\" \".join(sorted(list(x))) for xs in corpus.bi.values for x in xs])\n",
    "bi_u = [i.split(\" \") for i in list(val_ct_dict(bi).keys())]\n",
    "bi_u = list(zip(*bi_u))\n",
    "bigrams = pd.DataFrame(zip(bi_u[0],bi_u[1],val_ct_dict(bi).values()),columns=[\"bi1\",\"bi2\",\"cnt\"])\n",
    "bigrams = bigrams[bigrams[\"cnt\"]>=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "194fd293",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_from_bigram = pd.unique(bigrams[[\"bi2\",\"bi1\"]].values.ravel('K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "162014a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_bi = [bigrams.bi1.apply(embedd),bigrams.bi2.apply(embedd)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "79f80bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-SNE\n",
    "words_bi_embedded = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(embedd(words_from_bigram))\n",
    "#PCA\n",
    "# words_bi_embedded = PCA(n_components=2).fit_transform(embedd(words_from_bigram))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "ec06f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_bi_dict = dict(zip(words_from_bigram, words_bi_embedded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "1db554e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame(words_bi_embedded,columns=[\"x\",\"y\"])\n",
    "plot_df[\"words\"] = words_from_bigram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "f4cf413d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_283815/1610955349.py:7: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n",
      "/home/kwaks/gejopandas/lib/python3.10/site-packages/bokeh/models/plots.py:815: UserWarning: \n",
      "You are attempting to set `plot.legend.click_policy` on a plot that has zero legends added, this will have no effect.\n",
      "\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\n",
      "\n",
      "  warnings.warn(_LEGEND_EMPTY_WARNING % attr)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/kwaks/Desktop/ukraina/graf_bigramow.html'"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "from bokeh.plotting import figure, output_file, output_notebook, show , save\n",
    "from bokeh.models import HoverTool,BoxZoomTool,ResetTool, ColumnDataSource, Legend, LabelSet\n",
    "\n",
    "output_file(filename=\"graf_bigramow.html\", title=\"Graf bigramow\")\n",
    "\n",
    "\n",
    "timespan = range(2002,2021)\n",
    "hover = HoverTool()\n",
    "hover.tooltips = [\n",
    "(\"word\", \"@words\"),\n",
    "# (\"gęstość zaludnienia\", \"@density osób/km2\"),\n",
    "# (\"powierzchnia gminy zajeta przez park %\", \"@park_percent{0.2f} %\"),\n",
    "# (\"dochód na mieszkańca\", \"@y{int} zł\"),\n",
    "# (\"rok\", \"@x\"),\n",
    "]\n",
    "hover.formatters={'datetime': 'datetime'}\n",
    "\n",
    "\n",
    "zoom = BoxZoomTool()\n",
    "reset = ResetTool()\n",
    "\n",
    "graph = figure(title = \"bigrams t-sne\",\n",
    "               plot_width=1100, plot_height=900,\n",
    "#                tools=[hover]\n",
    "              ) \n",
    "#     graph.xaxis.axis_label = 'Rok'\n",
    "#     graph.yaxis.axis_label = 'Dochód [zł / osobę]'\n",
    "\n",
    "data = ColumnDataSource({\"x\": plot_df.x.values, \"y\": plot_df.y.values, \n",
    "                         \"words\": list(plot_df.words.values),\n",
    "\n",
    "                        })\n",
    "\n",
    "\n",
    "for bi1,bi2,cnt in zip(bigrams.bi1.values,bigrams.bi2.values,bigrams.cnt.values):\n",
    "    graph.line([words_bi_dict[bi1][0],words_bi_dict[bi2][0]], \n",
    "           [words_bi_dict[bi1][1],words_bi_dict[bi2][1]], \n",
    "                  color = \"red\", \n",
    "                  line_width=cnt*0.2,\n",
    "                  )\n",
    "graph.circle(\"x\", \"y\", source=data, size=10,color=\"navy\", alpha=1)\n",
    "\n",
    "labels = LabelSet(x='x', y='y', text='words',\n",
    "         x_offset=5, y_offset=5, source=data)\n",
    "graph.add_layout(labels)\n",
    "# graph.add_layout(graph.legend[0], 'right')\n",
    "graph.legend.click_policy=\"hide\"\n",
    "save(graph)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "63a63b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bi1</th>\n",
       "      <th>bi2</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>support</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>invasion</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>president</td>\n",
       "      <td>zelenskyyua</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>borisjohnson</td>\n",
       "      <td>prime_minister</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>arrive</td>\n",
       "      <td>uk</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>application</td>\n",
       "      <td>visa</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ally</td>\n",
       "      <td>work</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>ally</td>\n",
       "      <td>nato</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>agree</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              bi1             bi2  cnt\n",
       "0         support         ukraine   28\n",
       "1        invasion         ukraine   22\n",
       "2          people         ukraine   14\n",
       "3       president     zelenskyyua   13\n",
       "4    borisjohnson  prime_minister   13\n",
       "..            ...             ...  ...\n",
       "97         arrive              uk    3\n",
       "98    application            visa    3\n",
       "99           ally            work    3\n",
       "100          ally            nato    3\n",
       "101         agree         ukraine    3\n",
       "\n",
       "[102 rows x 3 columns]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc1583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
